\chapter{Informazione ed Entropia per variabili casuali discrete}
\label{cha:intro}




\section{Informazione}
\label{sec:informazione}
Fondamentali in questa tesi saranno i concetti di Informazione ed entropia.\\
Bisogna anzitutto specificare che in Probabilità il significato di Informazione ha un connotato diverso da quello della lingua parlata. Consideriamo ad esempio le seguenti frasi: 
\begin{enumerate}
\item[i.] Quando vado in palestra mi alleno
\item[ii.] Il vincitore delle prossime elezioni sarà Claudio Baglioni
\item[iii.] QUER W LKS E W
\end{enumerate}

istintivamente diremo che la frase contente maggior informazione è $(ii)$ in quanto contiene un'informazione totalmente nuova seguita poi da $(i)$ ed in fine $(iii)$ la quale non avendo significato non conterrà nessuna informazione.\\ Questa scala però tiene conto sia del significato della frase sia della quantità di \textit{sorpresa} che porta, in questo senso $(iii)$ non ha significato, ma porta \textit{sorpresa}, mentre $(ii)$ contiene sia significato che sorpresa.\\ Nel mondo della matematica si è visto che il concetto di significato è difficile da esprimere e si è dunque preferito puntare sul concetto di \textit{sorpresa} per esprimere il significato di \textit{informazione}.\\
Per definire in maniera rigorosa il nostro concetto di \textbf{informazione} poniamoci in uno spazio di probabilità \spacep.\\
Dati due eventi $E_1,E_2$ vogliamo che la nostra funzione d'informazione $I$ soddifi alcuni criteri:

\begin{enumerate} 
\item $I(E)\geq 0$ per ogni $E\in \mathcal{F}$
\item se \p$(E_1)\leq $ \p$(E_2)$ allora $I(E_1)\geq I(E_2)$ 
\item se $E_1,E_2$ sono indipendenti allora $I(E_1\cup E_2)=I(E_1)+ I(E_2)$
\end{enumerate} 
Con queste richieste ci viene naturalemte in mente una funzione che le soddisfa.

\begin{defi}
In uno spazio di probabilità \spacep definiamo la funzione $I: \mathcal{F}\to \mathbb{R}^+$ come:
\begin{equation}
(E)=-log_a(\mathbb{P} (E)).
\end{equation}
dove $a$ è una costante positiva (in alcuni testi la funzione viene moltiplicata per $K$,  ma tale costante è inutile dato che già scegliere la base coincide col moltiplicare per una costante infatti $log_a(x)=\frac{log_b(y)}{log_b(a)} \bigg)$.
\end{defi}

Si verifica facilmente che la funzione $I$ così definita rispetta le proprietà preposte, l'unico problema nasce per un evento $E$ tale che \p $(E)=0$ in questo caso $I(E)=\infty$, questa occorrenza può essere interpretata come l'incapacità di ottenere informazioni da un evento impossibile. La funzione \textit{Informazione} possiede inoltre la desiderabile proprietà di essere nulla qualora la probabilità di un evento sia $1$.\\
Essendo questa funzione spesso associata a codici si preferisce scegliere $2$ come base del logaritmo in questo modo supponendo di avere una variabile casuale $X$ con distribuzione di Bernoulli a parametro $p=\frac{1}{2}$ abbiamo che 
\begin{equation}
I(X=0)=I(X=1)=-log_2 \bigg(\frac{1}{2} \bigg ) =1
\end{equation}
Per questo d'ora in avanti con $log$ si intenderà $log_2$.

\section{Entropia}
\label{sec:Entropia}

Il secondo concetto fondamentale trattato in questa tesi è quello di \textit{entropia}.\\
Data una variabile casuale discreta $X$ a valori $\{ x_1...x_n \}$ e con legge di probabilità $\{p_1...p_n \}$ ($p_i:=\mathbb{P}(X=x_i)$) non possiam conoscere a priori il valore che assumerà $X$ e di conseguenza conoscere quanta informazione verrà inviata. Definiamo per questo l'\textit{entropia}.

\begin{defi}
si dice \textbf{entropia} di una variabile casuale discreta $X$ il valore
\begin{equation}
H(X):=\mathbb{E}(I(X))=-\sum_{j=1}^np_j\Phi(p_j)
\end{equation}
dove
$$\Phi(p):=
\systeme{
log_2(p)\ se \ p \neq 0 ,
0 \ se \  p=0}
$$
\end{defi}

Per convincersi della sensatezza di questa definizione si immagini di voler scommettere con una moneta modificata come segue:
\begin{enumerate}
\item esce testa con probabilità $p_1=0.95$
\item esce testa con probabilità $p_2=0.6$
\item esce testa con probabilità $p_3=0.5$
\end{enumerate} 
 usando la definizione di Entropia otteniamo:
 
 \begin{enumerate}
\item$H_1(p_1)=0.286$
\item$H_2(p_2)=0.971$
\item$H_3(p_3)=1$
\end{enumerate}
ovviamente nel primo caso la probabilità di predirre il risultato corretto è molto alta dato che la moneta è pesantemente modificata e infatti il sistema avrà una bassa entropia, nel secondo caso l'entropia aumenta nel terzo l'indecisione è massima e l'entropia di coneguenza ha anch'essa massimo.\\
Per convincersi di quanto detto in maniera più matematica si ha il seguente teorema:
\begin{teo} \label{teo:6.2}
Sia $X$ una variabile casuale discreta allora vale:
\begin{enumerate}
\item $H(X)\geq 0$ e $H(X)= 0$ se e solo se esiste un valore $X$, $x_1$ t.c. \p$(x_1)=1$
\item $H(X)\leq log(n)$ e l'uguaglianza varrà solo quando $X$ ha distribuzione uniforme
\end{enumerate}
\end{teo}
\begin{proof}
\begin{enumerate}
\item ovviamente $H(X)\geq 0$ perchè somma di quantità positive (consideriamo gli addendi come $-log(x)$). Supponiamo ora che $H(X)=0$ allora $p_jlog(p_j)=0 \forall j$, quindi abbiamo che $p_j$ sarà uguale ad 1 o 0, ma non può essere che tutti i $p_j$ siano  uguali a 0 e dunque deve esistere almeno un $p_j=1$.
\item  per prima cosa supponiamo che $p_j\ge 0$(nel caso non lo fossero basterebbe togliere i $c \  p_k=0$ e dimostrare che $H(X)\leq log(n-c)\leq log(n)$).\\
Dalla definizione abbiamo:
$$H(x)-log(n)=$$
$$=-\frac{1}{ln(2)} \bigg( \sumj p_j ln (p_j) + ln(n) \bigg)$$
$$=-\frac{1}{ln(2)} \bigg( \sumj p_j (ln (p_j) + ln(n)) \bigg)$$
$$=-\frac{1}{ln(2)} \bigg( \sumj p_j ln(p_jn)\bigg)$$
$$=\frac{1}{ln(2)} \bigg( \sumj p_j ln \bigg( \frac{1}{p_jn} \bigg) \bigg)$$
$$\leq \frac{1}{ln(2)} \bigg( \sumj p_j \bigg( \frac{1}{p_jn} -1 \bigg) \bigg)$$
$$= \frac{1}{ln(2)} \bigg( \sumj \bigg( \frac{1}{n} -p_j \bigg) \bigg)$$
$$\leq 0$$
dove nel terzultimo passaggio abbiamo usato il fatto che $ln(x)\leq x-1$ con l'uguaglianza solo se $X=1$. Quindi abbiamo che le disuguaglianza si trasformano in uguaglianze solo se $\frac{1}{p_jn}=1$ cioè se $p_j=\frac{1}{n}$ cioè la distribuzione uniforme.
\end{enumerate}
\end{proof}


\section{Unicità dell'Entropia}
\label{sec:UniEntropia}
Si può dimostrare che la scelta della funzione di entropia come \textit{misura di incertezza} è unica a meno di una costante moltiplicativa. Inanzitutto definiamo la \textit{misura di incertezza}:
\begin{defi}
sia \spacep un spazio di probabilità e $X$ variabile casuale di legge $\{ p_1....p_n \}$ , una funzione $U$ viene detta \textbf{misura di incertezza} se soddisfa le seguenti condizioni:
\begin{enumerate}
\item $U(X)$ è un massimo quando ha distribuzione uniforme
\item presa $Y$ variabile casuale allora $U(X,Y)=U_x(Y)+U(X)$
\item $U(p_1...p_n,0)=U(p_1...p_n)$
\item $U(p_1....p_n)$ è continua per tutti i suoi argomenti.
\end{enumerate}
\end{defi}

\begin{teo}
In uno spazio di probabilità \spacep consideriamo una variabile casuale $X$ con \lep allora\\
$U(X)$ è una misura di incertezza se e solo se 
$$U(X)= KH(X)$$
dove $K$ è una costante $K\geq 0$
\end{teo}


\section{Proprietà dell'entropia}
\label{sec:PropriEntropia}


\begin{defi} \label{defi:congiun}
Siano $X$ e $Y$ due variabili casuali definite sullo stesso spazio di probabilità, definiamo la loro \textbf{entropia congiunta} $H(X,Y)$ come:
\begin{equation}\label{eq:congiun}
H(X,Y):=-\sum_{j=1}^n\sum_{k=1}^m p_{jk}log(p_{jk})
\end{equation}
dove con $p_{jk}$ intendiamo \p$(X=j,Y=k)$
\end{defi}

Osserviamo subito che $H(X,Y)=H(Y,X)$.\\
Può essere interessante capire come si comporta l'entropia nel caso le variabili in considerazione siano dipendenti, per fare ciò definiremo l'\textit{entropia condizionata}, prima però un pò di notazione: chiameremo con $p_{j}(k)$ la probabilità condizionata che $Y=k$ sapendo che $X=j$.
\begin{defi} \label{defi:condiz}
La funzione $H_j(Y)$ sarà detta \textbf{entropia condizionale di $Y$ data $X=j$} dove
\begin{equation}\label{eq:6.6}
H_j(Y):=-\sum_{k=1}^m p_j(k)log(p_j(k))
\end{equation}
\end{defi}

Prendiamo una variabile casuale $X$ possiamo considerare ora la variabile casuale $H.(Y)$ che avrà immagine $\{H_1(Y)...H_n(Y) \}$ e legge di probabilità $\{ p _1...p_n\}$, $H.(Y)$ sarà quindi funzione di $X$.
\begin{defi}
definiamo l'\textbf{entropia condizionale di $Y$ data $X$}, $H_X(Y)$ come:
\begin{equation}\label{eq:6.7}
H_X(Y):= \mathbb{E}[H.(Y)]= \sum_{j=1}^n p_j H_j(Y)
\end{equation}
\end{defi}

\begin{lem} \label{lemma:6.8}
\begin{equation} \label{eq:6.8}
H_X(Y)=-\sum_{j=1}^n\sum_{k=1}^m p_{jk}log(p_j(k))
\end{equation}
\end{lem}
\begin{proof}
Sostituendo \ref{eq:6.6} in \ref{eq:6.7} otteniamo

\begin{equation} \label{eq:6.8.1}
H_X(Y)=-\sum_{j=1}^n\sum_{k=1}^m p_{j}p_j(k)log(p_j(k))
\end{equation}

Ricordando che 

$$p_j(k)=\mathbb{P}(Y=k|X=j)\ e \ p_j=\mathbb{P}(X=j)$$

otteniamo che 
$$p_j(k)p_j=\mathbb{P}(Y=k|X=j)\mathbb{P}(X=j)=\mathbb{P}(X=j,Y=k)=p_{jk}$$
e possiamo concludere.
\end{proof}


\begin{lem}
se $X$ e $Y$ sono indipendenti allora vale:
\begin{equation} \label{lemma:6.4}
H_X(Y)=H(Y)
\end{equation}
\end{lem}
\begin{proof}
supponiamo che la legge di probabilità di $Y$ sia $\{q_1...q_m\}$ allora ci basterà notare che nel caso in cui $X$ e $Y$ sono indipendenti $p_j(k)=\mathbb{P}(Y=k|X=j)=\mathbb{P}(Y=k)=q_k$
e dunque \ref{eq:6.8.1} diventa
$$H_X(Y)=-\sum_{k=1}^m q_klog(q_k)\sum_{j=1}^n p_{j}=-\sum_{k=1}^m q_klog(q_k)1=H(Y)$$
\end{proof}
\begin{teo} \label{teo:6.5}
Date due variabili casuali $X,Y$ vale:
\begin{equation}
H(X,Y)=H(X)+H_X(y).
\end{equation}
\end{teo}
\begin{proof}
sapendo che \p$(A\cup B)=\mathbb{P}(A|B)$\p$(B)$ quindi $p_{jk}=p_jp_j(k)$ sostituendo direttamente nella definizione di entropia congiunta \ref{defi:congiun} otteniamo
$$H(X,Y)=-\sum_{j=1}^n\sum_{k=1}^m p_{jk}log(p_{j}p_{j}(k))=-\sum_{j=1}^n\sum_{k=1}^m p_{jk}log(p_{j}(k))-\sum_{j=1}^n\sum_{k=1}^m p_{jk}log(p_{j})$$
possiamo concludere ricordando che $\sum_{k=1}^m p_{jk}=p_j$
\end{proof}
\begin{corol}
se $X$ e $Y$ sono indipendenti alora vale:
\begin{equation}
H(X,Y)=H(Y), H(Y)
\end{equation}
\end{corol}
\begin{proof}
basta applicare \ref{lemma:6.4} al teorema precedente
\end{proof}
\begin{teo} \label{teo:disugShannon}
\textbf{Disuguaglianza fondamentale di Shannon.}\\
\begin{equation}
H_X(Y)\leq H(Y)
\end{equation}
\end{teo}
\begin{proof}
per la dimostrazione usiamo la disuguaglianza di Jensen:\\
data $f$ funzione convessa vale
\begin{equation}
\sumj \lambda_j f(x_j)\geq f\bigg( \sumj \lambda_j x_j \bigg)
\end{equation}
con $\lambda_j > 0$ e $\sumj \lambda_j =1$
\end{proof}
per la dimostrazione si veda \cite{Jensen}
Ora applicando la disuguaglianza con:
$$\lambda_j=p_j,\ f(x)=x \log x, \  x_j=p_j(k)$$
per k fissato, otteniamo quindi:
$$\sumj p_j p_j(k)\log (p_j(k))\geq \sumj \bigg( p_j p_j(k) \bigg) \log \bigg( \sumj p_j p_j(k) \bigg)=q_k \log (q_k)$$
dove l'uguaglianza la ricaviamo da: $\sumj p_j p_j(k)=\sumj \bigg( \mathbb{P}(X=j) \mathbb{P}(Y=k|X=j) \bigg)= \mathbb{P}(Y=k)= q_k$.
Sommando su $k$ abbiamo che la parte sinistra della disuguaglianza diventa:
$$\sumj  p_j \sumk p_j(k) \log (p_j(k))=-\sumj p_j H_k(Y)=-H_X(Y)$$
mentre a destra otteniamo
$$\sumk q_k \log (q_k)= -H(Y)$$
e quindi:
\begin{equation}
-H_X(Y) \geq -H(Y)
\end{equation}
Questo risultato si può interpretare come il fatto che aggiungendo un informazione (il valore di $X$) l'entropia del sistema diminuisce.
Spesso è preferibile usare la notazione $H(Y|X)$ anzichè $H_X(Y)$ soprattutto nei casi in cui $X$ ha una definizione molto verbosa
\begin{oss}\label{oss:disugShannon}
Nel caso di processi stocastici (si veda \ref{sec:markEntropia}) è comodo osservare che considerando $Y=(X_n+1)$ e $X=X_0$ nel teorema precedente, si ottiene:
$$H(X_{n+1}|X_0,X_1...X_n) \leq H(X_{n+1}|X_1...X_n)$$
\end{oss}
\begin{defi}
date \var definiamo \textbf{mutua informazione di $X$ e $Y$}
\begin{equation} \label{defi:mutua}
I(X,Y):=H(Y)-H_X(Y)
\end{equation}
\end{defi}

Notiamo che $H_X(Y)$ è l'informazione contenuta in $Y$ che non è contenuta in $X$ e quindi l'informazione di $Y$ contenuta in $X$ sarà $H(Y)-H_X(Y)=I(X,Y)$
\begin{teo} \label{teo:6.7}
Per siano $X$ e $Y$ due variabili casuali con legge di probabilità rispettivamente \lep $\{q_1...q_n \}$
\begin{enumerate}
\item $I(X,Y)=\sumj \sumk p_{jk}log \bigg( \frac{p_{jk}}{p_j p_k} \bigg)$
\item $I(X,Y)=I(Y,X)$
\item se $X$ e $Y$ sono indipendenti allora $I(X,Y)=0$
\end{enumerate}
\end{teo}
\begin{proof}
si proceda come segue:
\begin{enumerate}
\item sempre ricordando che $\sum_{k=1}^m p_{jk}=p_j$ possiamo scrivere 
$$H(Y)=-\sumk q_{k}log (q_k)=-\sumj \sumk p_{jk} log (q_k)$$
e dunque per \ref{eq:6.8} otteniamo
$$I(X,Y)=-\sumj \sumk p_{jk}log(q_k)-\sumj \sumk p_{jk}log{p_j(k)}$$
\item imediato da 1.
\item semplicemente ricordando che se $X$ e $Y$ sono indipendenti $H_X(Y)=H(Y)$
\end{enumerate}
\end{proof}


\section{Principio della Massima Entropia}
\label{sec:maxEntropia}

Spesso ci si trova in condizioni in cui è data una variabile casuale $X$ a valori $\{ x_1...x_n \}$ di cui non si conosce la \lep  in questi casi si può applicare il principio di massima entropia:\\
\begin{defi}
Data una una variabile casuale $X$ con legge di probabilità \lep  incognita il \textbf{principio di massima entropia} ci impone di scegliere i $p_j$ in modo tale che $H(X)$ sia massima
\end{defi}
\textbf{Esempio.} 
Sia $X$ una variabile casuale a valori $\{ x_1...x_n \}$ di cui non si conosce la \lep . Sappiamo già che, se non ci sono altre condizioni, l'entropia sarà massima se $X$ sarà uniformemente distribuita. Prendiamo ora il caso in cui ci venga fornita la media di $\mathbb{E}[ X]=E$ troviamo il massimo dell'entropia $H(X)$ utilizzando i moltiplicatori di Lagrange:\\
come costrizioni abbiamo:
\begin{enumerate}
\item $\sumj p_j=1$
\item $\sumj x_j p_j=E$
\end{enumerate}
Dunque dobbiamo trovare il massimo valore di:
\begin{equation}
L(p_1...p_n;\lambda,\mu ):= -\sumj p_j log(p_j) + \lambda \bigg( \sumj p_j -1 \bigg) + \mu \bigg( \sumj x_j p_j - E \bigg)
\end{equation}
dove $\lambda \mu$ sono i moltiplicatori di Lagrange.\\
Imponendo le derivate parziali ugiali a 0 otteniamo:
$$\frac{\partial L}{\partial p_j}=-\frac{1}{ln(2)}(ln(p_j)+1)+\lambda + \mu x_j=0 \ \  (1\leq j \leq n) $$
$$quindi$$
$$p_j=e^{\lambda ' + \mu ' x_j} \ \ (1\leq j \leq n)$$
dove $\lambda ' = ln(2) \lambda -1 $ e $\mu ' = ln(2) \mu$\\
da 1. possimo ricaviamo 
$$\lambda ' = - ln(Z( \mu ')) \ dove \ Z( \mu '):= \sumj e^{\mu ' x_j}$$
riassumendo quindi abbiamo:
\begin{equation}
p_j=\frac{e^{\mu ' x_j}}{Z( \mu ')} \ \ (1\leq j \leq n)
\end{equation}



\section{Entropia nelle catene di Markov}
\label{sec:markEntropia}
\begin{defi}
Si pre una famiglia di variabili casuali tutta definite sullo stesso spazio di probabilità \spacep , $(X(t), t \geq 0 )$ è detta \textbf{processto stocastico}.
\end{defi}
Nella nostra trattazione ci limiteremo a considerare una piccola classe di processi stocastici chiamati catene di Markov.
\begin{defi} \label{defi:cateMarkov}
Un processo stocastico è detto \textbf{catena di Markov} se 
\begin{enumerate}
\item l'insieme $S$ che comprende i valori ammissibili delle variabili $X_n$ è discreto (se $S$ è denso si dirà processo di Markov)
\item possiede la 'proprietà di Markov' cioè
 $$\mathbb{P}(X_{n+1}=k_{n+1}|X_n=x_k..X_0=k_0)=\mathbb{P}(X_{n+1}=k_{n+1} | X_n=k_n)$$
\end{enumerate}
\end{defi}
Per i nostri scopi inoltre considereremo l'insieme del tempo come come un insieme discreto $\mathbb{N}$.\\
Infine definita $p_{ij}^n:=\mathbb{P}(X_{n+1}=j|X_n=i)$ vogliamo che la nostra matrice di transizione $P$, formata dai vari $p_{ij}$ sia stazionaria cioè:\\
$$p_{ij}^n=p_{ij}^0=: p_{ij} \  \forall n$$
Ci domandiamo ora se è sempre possibilie definire una catena di Markov $X=(X_n,n\in\mathbb{Z})$ per la quale ogni $X_n$ ammette entropia massima cioè per il teorema \ref{teo:6.2} $X_n$ ha distribuzione uniforme (se non vi sono altre restrizioni).
\begin{defi}
Una matrice A ad elementi positivi è detta \textbf{bistocastica} se per ogni riga e per ogni colonna la somma dei suoi elementi è pari ad 1.
\end{defi}
\begin{teo}
Una catena di Markov con matrice di transizione $P$ ammette la distribuzione uniforme come distribuzione invariante se e solo se $P$ è bistocastica
\end{teo}
\begin{proof}
Se $P$ è bistocastica allora $ \sumi P_{ij}=1 \forall 1\leq j \leq N$ e quindi:
$$\sumi \frac{1}{N}P_{ij}=\frac{1}{N}\sumi P_{ij}=\frac{1}{N}$$
e quindi $\frac{1}{N}$ è una distribuzione invariante.\\
Supponiamo ora che la distribuzione uniforme sia invariante e dimostriamo che $P$ è bistocastica. Procedendo al contrario di prima abbiamo:
$$\frac{1}{N}=\frac{1}{N} \sumi P_{ij} \Rightarrow \sumi P_{ij}=1$$
Abbiamo che per ogni colonna la somma dei suoi elementi è 1, quindi possiamo concludere\\
???????????????????????????????????????????????????????????.
\end{proof}

\begin{defi}
Siano $X$ e $Y$ due variabili casuali della stessa dimensione.
Definiamo \textbf{entropia relativa} il valore:
\begin{equation}
D(X,Y):=\sumj p_j log \bigg( \frac{p_j}{q_j} \bigg)
\end{equation}
\end{defi}
\begin{teo}
\begin{enumerate}
Per l'entropia relativa vale:
\item $D(X,Y)\geq 0, =$ se e solo se $X$ e $Y$ sono identicamente distribuite
\item se $Y$ è uniformemente distribuita allora vale
\begin{equation}
D(X,Y)=log(N)-H(X)
\end{equation}
\end{enumerate}
\end{teo}
\begin{defi}
Un processo stocastico è detto \textbf{stazionario} se presi $m,k\in \mathbb{N}$ vale:
$$\mathbb{P}(X_{n_1}=i_1...X_{n_k}=i_k)= \mathbb{P}(X_{n_1+m}=i_1...X_{n_k+m}=i_k) \ \forall i_s \in S$$
\end{defi}
Consideriamo una catena di Markov stazionaria $(X_n,n \in \mathbb{Z}_+)$ con una matrice di transizione bistocastica $P$ e sia $X_{\infty}$ uniformemente distribuita, abbiamo quindi che $D(X_n,X_{\infty})=log(N)-H(X_n)$. Si dimostra che $D(X_n,X_{\infty})$ è una funzione decrescente e che se la distribuzione uniforma è l'unica distribuzione stazionaria, allora $lim_{n \to \infty}D(X_n,X_{\infty})=0$. Segue quindi che $H(X_n)$ è crescente. \cite{Thomas}



\section{La Regola della Catena}
\label{sec:chainRule}
Vediamo ora come cambia l'informazione in un processo stocastico. Lapprocio più naturale può sembrare quelo di considerare l'entropia come funzione del tempo, in questo modo però ci si dimentica della relazione tra due passaggi dal tempo $t_n$ al tempo $t_{n+1}$. Estendiamo la definizione di entropia congiunta \ref{defi:congiun} in questo modo:
\begin{equation}
H(X_0...X_n):=- \suma p(i_0...i_n)log(p(i_o...i_n)).
\end{equation}
Mentre la definizione di entropia condizionata \ref{defi:condiz} multivatiata diventa:
\begin{equation}
H(Y|X_1...X_n)=-\sum_{j,i_1...i_n=1}^N \mathbb{P}(Y=j,X_1=i_1...X_n=i_n) log(\mathbb{P}(Y=j|X_1=i_1...X_n=i_n))
\end{equation}
Non ci rimane che generalizzare il teorema \ref{teo:6.5}.
\begin{teo} \label{teo:chainRule}
\textbf{Regola della catena}
\begin{equation}
H(X_0...X_n)=H(X_0)+\sum_{i=1}^n  H(X_i|X_0,...X_{i-1})=H(X_0)+H(X1|X_0)+...+H(X_n|X_0...X_{n-1})
\end{equation}
Inoltre l'entropia cresce al crescere di n.
\end{teo}
\begin{proof}
Procediamo per induzione:\\
Il caso base con $n=1$ è esattamente il teorema \ref{teo:6.5}, procediamo con il passo induttivo. Uindi assumiamo che valga per $n$, dimostriamo che vale per $n+1$.
$$H(X_0...X_n, X_{n+1})=- \sumaa p(i_0...i_n,i_{n+1})log(p(i_o...i_n,i_{n+1}))$$
$$= - \sumaa p(i_0...i_n,i_{n+1})log(\mathbb{p}(_{n+1}=i_{n+1}|X_0=i_0,...X_n=i_n))-\sumaa p(i_0...i_n,i_{n+1})log(p(i_0...i_n))$$
dato che 
$$\sumaa p(i_0...i_{n+1})log(p(i_0...i_n))=\suma p(i_0...i_{n})log(p(i_0..i_n))$$
abbiamo che
\begin{equation}\label{eq:10.8}
H(X_0...X_n+1)=H(X_0...X_n)+H(X_{n+1}|X_0...X_n)
\end{equation}
Applicando l'ipotesi induttiva otteniamo il risultato.
Inoltre da \ref{eq:10.8} e dal fatto che l'entropia è sempre maggiore di zero otteniamo che l'entropia cogniunta cresce nel tempo.
\end{proof}


\section{Velocità dell'Entropia}
\label{sec:EntropyRate}
\begin{defi}
Quando il limite esiste, $h(X)$ si dice \textbf{velocità dell'entropia} dove
$$h(X):=\limi\frac{1}{n}H(X_0...X_{n-1})$$
\end{defi}

\begin{teo}\label{teo:10.10}
se $X=(X_i,i\in \mathbb{N})$ è un processo stocastico stazionario, allora $h(X)$ esiste e:
\begin{equation} \label{eq3}
h(X)=\limi H(X_{n-1}|X_0...X_{n-2})
\end{equation}
\end{teo}
\begin{proof}
Applicando la regola della catena \ref{teo:chainRule} otteniamo subito che
\begin{equation}\label{eq4}
h(X)=\limi \frac{1}{n} H(X_0...X_{n-1})= \limi \frac{1}{n} \sum_{i=0}^{n-1}H(X_i|X_0...X_{i-1})
\end{equation}
Passiamo ora a dimostrare l'esistenza del secondo membro di \ref{eq3}:\\
dall'osservazione \ref{oss:disugShannon} otteniamo:
\begin{equation} \label{eq1}
H(X_{n+1}|X_0,X_1...X_n) \leq H(X_{n+1}|X_1...X_n)
\end{equation}
Grazie al Teorema \ref{teo:6.5} possiamo scrivere:
$$H(X_{n+1}|X_1...X_n)=H(X_{n+1},X_1...X_n) - H(X_1....X_n)$$
e ricordandoci che il processo è stazionario abbiamo:
$$H(X_{n+1},X_1...X_n) - H(X_1....X_n)= H(X_{n},X_0...X_{n-1}) - H(X_0....X_{n-1})$$
infine applicando il Teorema \ref{teo:6.5} in modo inverso rispetto a prima
$$H(X_{n},X_0...X_{n-1}) - H(X_0....X_{n-1})=H(X_{n}|X_0...X_{n-1})$$
riassumendo quindi
\begin{equation} \label{eq2}
H(X_{n+1}|X_1...X_n)=H(X_{n}|X_0...X_{n-1})
\end{equation}
Sostituendo \ref{eq2} in \ref{eq1} otteniamo:
\begin{equation}
H(X_{n+1}|X_0,X_1...X_n) \leq H(X_{n}|X_0...X_{n-1})
\end{equation}
Qundi definendo $a_n :=  H(X_{n}|X_0...X_{n-1})$ otteniamo una successione $\{ a_n \}_{n\in \mathbb{N}}$ monotona non crescente limitata dal basso visto che $a_k=H(X_{k}|X_0...X_{k-1})\geq 0$ e dunque $\limi a_n$ esiste ed è finito dato che $H(Y)<\infty$.
Proviamo adesso che la serie $\frac{1}{n} \sumin a_i = a$ dove $a:=\limi a_n$:
$$\limi \bigg| \frac{1}{n} \sumin a_i-a \bigg| \leq \limi \frac{1}{n} \sumin |a_i-a| = \limi \frac{1}{n} \sum_{i=1}^{N_0} |a_i-a| + \sum_{i=N_0+1}^{n} |a_i-a|= \limi \sum_{i=N_0+1}^{n} |a_i-a|$$
E da qui possiamo concludere scegliendo $N_0$ tale che $\frac{1}{n}|a_i-a|$ sia piccolo a piacere cosa sempre possibilie dato che $\limi a_n=a$.\\
Ricordando come abbiamo definito $a_n$ otteniamo quindi:
\begin{equation}
\limi H(X_{n-1}|X_0...X_{n-2})=\limi \frac{1}{n} \sum_{i=0}^{n-1}H(X_i|X_0...X_{i-1})
\end{equation}
ricordando inifine \ref{eq4} possiamo concludere:
$$h(X)=\limi \frac{1}{n} H(X_0...X_{n-1}) = \limi H(X_{n-1}|X_0...X_{n-2}).$$
\end{proof}
\begin{teo}
Se $(X_i\in \mathbb{N})$ è una catena di Markov stazionaria con distribuzione iniziale $\pi^{(0)}$ e matrice di transizione $P$ allora vale
\begin{equation}
h(X)=\sumij \pi^{(0)} P_{ij} \log (P_{ij})
\end{equation}
\end{teo}
\begin{proof}
dal teorema preedente \ref{teo:10.10} abbiamo:
$$h(X)=\limi H(X_{n-1}|X_0...X_{n-2})$$
$$=\limi H(X_{n-1}|X_{n-2})$$
$$=H(X_1|X_2)$$
$$=\sumij \mathbb{P}(X_0=i,X_1=j)\log (P_{ij})$$
$$=\sumij \mathbb{P}(X_0=i)P_{ij}\log (P_{ij})$$
$$=\sumij \pi^{(0)}P_{ij}\log (P_{ij})$$
Dove per passare dalla prima alla seconda riga abbiamo usato la 'proprietà di Markov' \ref{defi:cateMarkov}, per passare dalla seconda alla terza abbiamo usato il fatto che il processo è stazionario, dalla terza alla quarta il lemma \ref{lemma:6.8}
\end{proof}





