\chapter{Conclusioni}
\label{cha:conclusioni}
Concludendo questo elaborato va evidenziato come alcuni dei risultati trovati concordano pienamente con l'idea intuitiva che possiamo avere di entropia, altri, come il teorema Fondamentale di Shannon, richiedono uno studio più approfondito per essere compresi appieno.\\
A titolo d'esempio si considerino due disuguaglianze: $H(X)\leq(n)$ \ref{teo:6.2} e la \textit{disuguaglianza di Shannon} \ref{teo:disugShannon} ($H_X(Y)\leq H(Y)$). La prima delle due mostra come aumentando $n$ cioè aumentando i possibili risultati di $X$ l'andamento  del sistema diventa più imprevedibile e ed infatti il tetto massimo dell'entropia, $\log(n)$, continua a crescere. La \textit{disuguaglianza di Shannon} invece descrive come si comporta l'entropia di una variabile casuale $Y$ nel caso in cui vengano fornite nuove informazioni e quindi nel caso il sistema diventi più prevedibile.\\ 
Un commento particolare lo merita l'ultimo teorema dimostrato. Infatti se ci si concentra solo sulla riduzione dell'errore commesso si può essere portati a sottovalutare la portata del teorema di Shannon.Infatti per ridurre l'inesattezza si potrebbe semplicemente pensare di inviare più volte il simbolo che deve essere inviato, in questo modo, essendo $p<\frac{1}{2}$ la probabilità d'errore per ogni simbolo inviato, avremmo che affinché il sistema registri un errore nella ricezione servirebbe che almeno $\frac{n}{2}$ simboli fossero errati. Questo evento verrebbe modellizzato attraverso una variabie casuale binomiale che, al crescere di $n$, farebbe tendere la probabilità di tale evento a zero. Questo procedimento però, all'aumentare di $n$ ridurrebbe la velocità di trasmissione d'informazione mandando anch'essa a zero. La forza del \textit{teorema fondamentale di Shannon} sta proprio in quest'osservazione. Il teorema infetti garantisce l'esistenza di un codice che, mandando a zero l'errore commesso, mantiene comunque la velocità di trasmissione di informazione arbitrariamente vicina alla capacità del canale. Purtroppo questo teorema però non è del tipo costruttivo, non ci fornisce cioè un metodo per la creazione di tale codice lasciandone quindi ancora aperta la ricerca.\\
È stato dimostrato che l'inverso non è possibile cioè non si può avere una probabilità d'errore arbitrariamente piccola se si trasmette ad una capacità superiore a quella del canale.\\
Come accennato nella discussione del teorema ricordiamo che  è stato dimostrata la possibilità non solo di poter controllare la media di errore, ma anche quella massima ($\max_{1\leq i \leq M} \mathbb{P}(E|x_i)$).\\







