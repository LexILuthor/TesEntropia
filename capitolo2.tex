\chapter{Entropia per Variabili Casuali Assolutamente Continue}
In questo capitolo estenderemo la definizione di entropia data per il caso di una variabile aleatoria discreta al caso in cui la nostra variabile casuale $X$ sia assolutamente continua.

\begin{defi}
Data una variabile casuale $X$, chiamiamo \textbf{funzione di distribuzione di X} l'applicazione $F_X: \mathbb{R} \to \mathbb{R}$ data da:
$$F_X(t):= \mathbb{P}(X \in (-\infty,t])$$
\end{defi}
\begin{defi}
Una funzione di distribuzione $F$ è detta \textbf{assolutamente continua} se esiste una funzione $f \in L^1(\mathbb{R})$, $f\geq 0$ e $\int_{\mathbb{R}} f(u)du=1$ tale che:
\begin{equation}\label{eq:assConti}
F(t)=\int_{-\infty }^t f(u)du, \  t\in \mathbb{R}
\end{equation}
dove l'integrale è definito nel senso di Lebesgue. Tale $f$ verrà detta \textbf{funzione di densità}\\
Una variabile casuale che ha funzione di distribuzione della forma \ref{eq:assConti} è detta \textbf{variabile casuale assolutamente continua}
\end{defi}
Per le proprietà degli elementi appena definiti si veda \cite{Mazzucchi}

\section{Entropia nel caso Continuo}
\label{sec:EntropiaContinuo}
\begin{defi}
Sia $X$ una variabile casuale con immagine $(a,b)$ e funzione di densità $f$. $H(X)$ detta \textbf{entropia di X} dove:
$$H(X)=-\int_a^b \log(f(x))f(x)dx= \mathbb{E}\bigg[ \log \bigg( \frac{1}{f(X)} \bigg) \bigg]$$
\end{defi}
Anche qui per convenzione $\log$ sarà il logaritmo in base 2.\\
Purtroppo la proprietà di essere misura di incertezza, valida nel caso discreto \ref{teo:misuraIncertezza}, non è più valida con questa definizione.\\
Questo deriva dal fatto che, mentre nel caso discreto l'argomento del logaritmo è sempre compreso tra 0 e 1, nel caso continuo la funzione di densità può assumere valori su tutto $\mathbb{R}$. finisco dmani
 sfmldsalkàgbdhviahvbs







