\chapter*{Introduzione} % senza numerazione
\label{sommario}

\addcontentsline{toc}{chapter}{Sommario} % da aggiungere comunque all'indice
Questa tesi si pone l'obiettivo di esplorare i concetti di Entropia ed Informazione, così come presentati nel lavoro di Claude Shannon \cite{Shannon} concentrandosi maggiormente su variabili casuali discrete.\\
Il campo dove questa teoria trova maggior applicazione è sicuramente la teoria dei codici cui verrà prestata una particolare attenzione. Ci si soffermerà soprattutto sui codici binari, i quali, attraverso i computer si sono ormai inseriti in modo indelebile nella nostra quotidianità. La portata di questi teoremi non si deve però pensare limitata a codici informatici, ma ad ogni tipo di codice che si possa definire tale, primo fra tutti il DNA il quale, grazie alla sua composizione di basi azotate, permette la codifica di amminoacidi fondamentali per la nostra esistenza. Queste applicazioni dimostrano ancora una volta che la Matematica, nonostante venga ritenuta una scienza astratta, è in grado di rapportarsi con la nostra realtà e ci indirizza nella sua comprensione.\\
Verrà riservato un accenno anche al \textit{caso continuo} il quale purtroppo non ammette uno studio così elegante e proficuo a causa della mancanza di controllo che si può esercitare sulla funzione di densità di una variabile assolutamente continua.\\
Il "teorema fondamentale di Shannon" ci garantirà infine l'esistenza di codici che, senza ridurre la velocità di trasmissione del messaggio, forniscono una probabilità d'errore arbitrariamente piccola, permettendoci quindi di rivolgere le nostre attenzioni allo studio di nuovi codici piuttosto che alla costruzione di canali comunicativi.


\clearpage


