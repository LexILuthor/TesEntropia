\chapter*{Sommario} % senza numerazione
\label{sommario}

\addcontentsline{toc}{chapter}{Sommario} % da aggiungere comunque all'indice
In questa tesi verranno esplorati i concetti di Entropia ed Informazione così come presentati nel lavoro di Claude Shannon \cite{Shannon}, concentrandosi maggiormente su variabili casuali discrete.\\
Il campo in cui questa teoria trova maggior applicazione è sicuramente la teoria dei codici, Qui verrà prestata particolare attenzione ai codici binari i quali attraverso i computer sono ormai inseriti in modo indelebile nella nostra quotidianità. La portata di questi teoremi non si deve però pensare limitata a codici informatici, ma a ogni tipo di codice che si possa definire tale, primo fra tutti il DNA il quale grazie alla sua composizione di basi azotate permette la codifica di amminoacidi fondamentali per la nostra esistenza. Queste applicazioni dimostrano ancora una volta che, nonostante la concezione della Matematica come una scienza astratta, essa è comunque in grado di interfacciarsi con la nostra realtà e ci può indirizzare nella comprensione di essa.
Il "teorema fondamentale di Shannon" ci garantirà poi l'esistenza di codici che messi all'interno di canali comunicativi che permettono di rendere la probabilità d'errore arbitrariamente piccola, permettendoci quindi di rivolgere le nostre attenzioni allo studio dei codici piuttosto che a quello della costruzione di canali comunicativi
Verrà fatto un accenno anche al caso continuo il quale purtroppo non ammette uno studio così elegante e proficuo a causa della mancanza di controllo che si può esercitare sulla funzione di densità di una variabile assolutamente continua...




